{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Emotion Recogination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference : https://www.kaggle.com/aroraumang/facial-emotion-recogination-82-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       angry  happy  neutral\n",
      "train   3860   6722     4648\n",
      "sum of train :  15230\n",
      "      angry  happy  neutral\n",
      "test    907   1621     1101\n",
      "sum of test :  3629\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'fer2013/modified/train/'\n",
    "test_dir = 'fer2013/modified/test/'\n",
    "\n",
    "row, col = 48, 48\n",
    "classes = 3\n",
    "emotion_labels = ['angry', 'happy', 'neutral']\n",
    "\n",
    "def count_exp(path, set_):\n",
    "    dict_ = {}\n",
    "    for expression in os.listdir(path):\n",
    "        dir_ = path + expression\n",
    "        dict_[expression] = len(os.listdir(dir_))\n",
    "    df = pd.DataFrame(dict_, index=[set_])\n",
    "    return df\n",
    "train_count = count_exp(train_dir, 'train')\n",
    "test_count = count_exp(test_dir, 'test')\n",
    "print(train_count)\n",
    "print('sum of train : ', sum(train_count.iloc[0]))\n",
    "print(test_count)\n",
    "print('sum of test : ', sum(test_count.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of number of images in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_count.transpose().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of number of images in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_count.transpose().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 3)\n",
      "(48, 48, 3)\n",
      "(48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1584 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,22))\n",
    "i = 1\n",
    "for expression in os.listdir(train_dir):\n",
    "    img = load_img((train_dir + expression +'/'+ os.listdir(train_dir + expression)[1]))\n",
    "    print(np.asarray(img).shape)\n",
    "    plt.subplot(1,7,i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(expression)\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15230 images belonging to 3 classes.\n",
      "Found 3629 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=(1./255 - 0.5)*2.0,\n",
    "                                   zoom_range=0.3,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                batch_size= 64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=(1./255 - 0.5)*2.0)\n",
    "test_set = test_datagen.flow_from_directory(test_dir,\n",
    "                                                batch_size= 64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x1a20681e848>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0, 'happy': 1, 'neutral': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, classes=3):\n",
    "     #Initialising the CNN\n",
    "    model = tf.keras.models.Sequential()   \n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =input_size))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    #Compliling the model\n",
    "    model.compile(optimizer=Adam(lr=0.0001, decay=1e-6), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 22, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              31720448  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 32,112,643\n",
      "Trainable params: 32,112,003\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fernet = get_model((row,col,1), classes)\n",
    "fernet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydot\n",
    "#!pip install graphviz\n",
    "#!pip install pydotplus\n",
    "#!pip install django-extensions\n",
    "#!pip install pyparsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_model(fernet, to_file='fernet.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_path = 'models_1_2/{epoch:02d}-{val_accuracy:.2f}.h5'\n",
    "log_dir = \"models_1_2/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=chk_path,\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             moniter='val_loss')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', \n",
    "                          min_delta=0, \n",
    "                          patience=3, \n",
    "                          verbose=1, \n",
    "                          restore_best_weights=True)\n",
    "                        \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.2, \n",
    "                              patience=6, \n",
    "                              verbose=1, \n",
    "                              min_delta=0.0001)\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "237/237 [==============================] - 588s 2s/step - loss: 4.7734 - accuracy: 0.4343 - val_loss: 3.3539 - val_accuracy: 0.5748\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.35387, saving model to models_1_2\\01-0.57.h5\n",
      "Epoch 2/60\n",
      "237/237 [==============================] - 575s 2s/step - loss: 3.3297 - accuracy: 0.5453 - val_loss: 3.0025 - val_accuracy: 0.6320\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.35387 to 3.00254, saving model to models_1_2\\02-0.63.h5\n",
      "Epoch 3/60\n",
      "237/237 [==============================] - 571s 2s/step - loss: 3.0368 - accuracy: 0.5734 - val_loss: 2.6974 - val_accuracy: 0.6582\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.00254 to 2.69742, saving model to models_1_2\\03-0.66.h5\n",
      "Epoch 4/60\n",
      "237/237 [==============================] - 577s 2s/step - loss: 2.7526 - accuracy: 0.6012 - val_loss: 2.4156 - val_accuracy: 0.6752\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.69742 to 2.41557, saving model to models_1_2\\04-0.68.h5\n",
      "Epoch 5/60\n",
      "237/237 [==============================] - 585s 2s/step - loss: 2.4569 - accuracy: 0.6274 - val_loss: 2.1675 - val_accuracy: 0.6914\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.41557 to 2.16748, saving model to models_1_2\\05-0.69.h5\n",
      "Epoch 6/60\n",
      "237/237 [==============================] - 568s 2s/step - loss: 2.1999 - accuracy: 0.6523 - val_loss: 1.9356 - val_accuracy: 0.7065\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.16748 to 1.93561, saving model to models_1_2\\06-0.71.h5\n",
      "Epoch 7/60\n",
      "237/237 [==============================] - 575s 2s/step - loss: 1.9650 - accuracy: 0.6648 - val_loss: 1.7306 - val_accuracy: 0.7129\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.93561 to 1.73057, saving model to models_1_2\\07-0.71.h5\n",
      "Epoch 8/60\n",
      "237/237 [==============================] - 574s 2s/step - loss: 1.7691 - accuracy: 0.6844 - val_loss: 1.5441 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.73057 to 1.54414, saving model to models_1_2\\08-0.74.h5\n",
      "Epoch 9/60\n",
      "237/237 [==============================] - 566s 2s/step - loss: 1.6033 - accuracy: 0.7025 - val_loss: 1.3907 - val_accuracy: 0.7517\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.54414 to 1.39067, saving model to models_1_2\\09-0.75.h5\n",
      "Epoch 10/60\n",
      "237/237 [==============================] - 567s 2s/step - loss: 1.4430 - accuracy: 0.7151 - val_loss: 1.2785 - val_accuracy: 0.7520\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.39067 to 1.27846, saving model to models_1_2\\10-0.75.h5\n",
      "Epoch 11/60\n",
      "237/237 [==============================] - 569s 2s/step - loss: 1.3399 - accuracy: 0.7155 - val_loss: 1.1806 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.27846 to 1.18057, saving model to models_1_2\\11-0.76.h5\n",
      "Epoch 12/60\n",
      "237/237 [==============================] - 561s 2s/step - loss: 1.2246 - accuracy: 0.7340 - val_loss: 1.0846 - val_accuracy: 0.7642\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.18057 to 1.08463, saving model to models_1_2\\12-0.76.h5\n",
      "Epoch 13/60\n",
      "237/237 [==============================] - 567s 2s/step - loss: 1.1328 - accuracy: 0.7378 - val_loss: 0.9886 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.08463 to 0.98858, saving model to models_1_2\\13-0.78.h5\n",
      "Epoch 14/60\n",
      "237/237 [==============================] - 561s 2s/step - loss: 1.0555 - accuracy: 0.7475 - val_loss: 0.9239 - val_accuracy: 0.7899\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.98858 to 0.92389, saving model to models_1_2\\14-0.79.h5\n",
      "Epoch 15/60\n",
      "237/237 [==============================] - 564s 2s/step - loss: 0.9681 - accuracy: 0.7624 - val_loss: 0.8721 - val_accuracy: 0.7963\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.92389 to 0.87208, saving model to models_1_2\\15-0.80.h5\n",
      "Epoch 16/60\n",
      "237/237 [==============================] - 562s 2s/step - loss: 0.9246 - accuracy: 0.7573 - val_loss: 0.8138 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.87208 to 0.81382, saving model to models_1_2\\16-0.80.h5\n",
      "Epoch 17/60\n",
      "237/237 [==============================] - 563s 2s/step - loss: 0.8581 - accuracy: 0.7787 - val_loss: 0.7815 - val_accuracy: 0.8058\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.81382 to 0.78148, saving model to models_1_2\\17-0.81.h5\n",
      "Epoch 18/60\n",
      "237/237 [==============================] - 563s 2s/step - loss: 0.8205 - accuracy: 0.7750 - val_loss: 0.7520 - val_accuracy: 0.7896\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.78148 to 0.75196, saving model to models_1_2\\18-0.79.h5\n",
      "Epoch 19/60\n",
      "237/237 [==============================] - 562s 2s/step - loss: 0.7831 - accuracy: 0.7823 - val_loss: 0.7045 - val_accuracy: 0.8142\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.75196 to 0.70454, saving model to models_1_2\\19-0.81.h5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't write data (file write failed: time = Wed May 12 22:08:59 2021\n, filename = 'models_1_2\\19-0.81.h5', file descriptor = 6, errno = 28, error message = 'No space left on device', buf = 000001A225786040, total write size = 126877696, bytes this sub-write = 126877696, bytes actually written = 18446744073709551615, offset = 1591680)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d2f69efcfacb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                  \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                  \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                  validation_steps=validation_steps)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epoch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1416\u001b[0m                         'directory: {}'.format(filepath))\n\u001b[0;32m   1417\u001b[0m         \u001b[1;31m# Re-throw the error for any other causes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_file_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1394\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[0;32m   1395\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1396\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1397\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2000\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 2002\u001b[1;33m                     signatures, options, save_traces)\n\u001b[0m\u001b[0;32m   2003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m   def save_weights(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    152\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m    153\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 154\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    155\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[0mmodel_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;31m# TODO(b/128683857): Add integration tests between tf.keras and external\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[0mparam_dset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m         \u001b[0mparam_dset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensor\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, args, val)\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.H5PY_H5Dwrite\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Can't write data (file write failed: time = Wed May 12 22:08:59 2021\n, filename = 'models_1_2\\19-0.81.h5', file descriptor = 6, errno = 28, error message = 'No space left on device', buf = 000001A225786040, total write size = 126877696, bytes this sub-write = 126877696, bytes actually written = 18446744073709551615, offset = 1591680)"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // training_set.batch_size\n",
    "validation_steps = test_set.n // test_set.batch_size\n",
    "\n",
    "hist = fernet.fit(x=training_set,\n",
    "                 validation_data=test_set,\n",
    "                 epochs=60,\n",
    "                 callbacks=callbacks,\n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accu = fernet.evaluate(training_set)\n",
    "test_loss, test_accu = fernet.evaluate(test_set)\n",
    "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_accu*100, test_accu*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fernet.save_weights('model_bestweight_1_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fernet.save('model_best_1_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix and Classification on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = np.random.permutation(training_set.n)\n",
    "training_set.index_array = per\n",
    "classes = training_set.classes[per]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fernet.predict(training_set)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "class_labels = test_set.class_indices\n",
    "class_labels = {v:k for k,v in class_labels.items()}\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm_train = confusion_matrix(classes, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm_train)\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cm_train, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_mark = np.arange(len(target_names))\n",
    "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
    "_ = plt.yticks(tick_mark, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix and Classification on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = np.random.permutation(test_set.n)\n",
    "test_set.index_array = per\n",
    "classes = test_set.classes[per]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fernet.predict(test_set)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "class_labels = test_set.class_indices\n",
    "class_labels = {v:k for k,v in class_labels.items()}\n",
    "\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm_test = confusion_matrix(classes, y_pred)\n",
    "print('Confusion Matrix')\n",
    "print(cm_test)\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cm_test, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_mark = np.arange(len(target_names))\n",
    "_ = plt.xticks(tick_mark, target_names, rotation=90)\n",
    "_ = plt.yticks(tick_mark, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단일 사진 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 3224,
     "status": "error",
     "timestamp": 1616042602948,
     "user": {
      "displayName": "김도희",
      "photoUrl": "",
      "userId": "10132062117470386363"
     },
     "user_tz": -540
    },
    "id": "I17bsrawFQ8B",
    "outputId": "6533194d-9762-41c5-821d-a497fa1de839"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "#from google.colab.patches import cv2_imshow\n",
    " \n",
    "# parameters for loading data and images\n",
    "detection_model_path = 'haarcascade_files/haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = 'fernet_best_1_2.h5'\n",
    "img_path =  \"angry.jpg\" # sys.argv[1]\n",
    " \n",
    "# hyper-parameters for bounding boxes shape\n",
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = ['angry', 'happy', 'neutral'] # , 'sad']\n",
    "            \n",
    " \n",
    "# reading the frame\n",
    "orig_frame = cv2.imread(img_path)\n",
    "#print(img_path)\n",
    "#print(orig_frame)\n",
    "frame = cv2.imread(img_path,0)\n",
    "#print(frame)\n",
    "faces = face_detection.detectMultiScale(frame,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    " \n",
    "if len(faces) > 0:\n",
    "    print(faces)\n",
    "    faces = sorted(faces, reverse=True,key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "    (fX, fY, fW, fH) = faces\n",
    "    roi = frame[fY:fY + fH, fX:fX + fW]\n",
    "    roi = cv2.resize(roi, (48, 48))\n",
    "    roi = roi.astype(\"float\") / 255.0\n",
    "    roi = img_to_array(roi)\n",
    "    roi = np.expand_dims(roi, axis=0)\n",
    "    preds = emotion_classifier.predict(roi)[0]\n",
    "    emotion_probability = np.max(preds)\n",
    "    label = EMOTIONS[preds.argmax()]\n",
    "    cv2.putText(orig_frame, label, (fX, fY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "    cv2.rectangle(orig_frame, (fX, fY), (fX + fW, fY + fH),(0, 0, 255), 2)\n",
    " \n",
    "cv2.imshow('test_face', orig_frame)\n",
    "#cv2_imshow(orig_frame)\n",
    "cv2.imwrite('test_output/'+img_path.split('/')[-1],orig_frame)\n",
    "if (cv2.waitKey(0) and 0xFF == ord('q')):\n",
    "    sys.exit(\"Thanks\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실시간 영상을 통한 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 4611,
     "status": "ok",
     "timestamp": 1616042544146,
     "user": {
      "displayName": "김도희",
      "photoUrl": "",
      "userId": "10132062117470386363"
     },
     "user_tz": -540
    },
    "id": "-YP916SJFQ8F",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: fernet_best_1_2.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-5b6bea2c21a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# loading models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mface_detection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_detection_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetection_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0memotion_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memotion_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# getting input model shapes for inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    112\u001b[0m                   (export_dir,\n\u001b[0;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: fernet_best_1_2.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "from statistics import mode\n",
    "\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from utils.datasets import get_labels\n",
    "from utils.inference import detect_faces\n",
    "from utils.inference import draw_text\n",
    "from utils.inference import draw_bounding_box\n",
    "from utils.inference import apply_offsets\n",
    "from utils.inference import load_detection_model\n",
    "from utils.preprocessor import preprocess_input\n",
    "\n",
    "# parameters for loading data and images\n",
    "detection_model_path = 'haarcascade_files/haarcascade_frontalface_default.xml'\n",
    "#emotion_model_path = 'ferNet.h5'\n",
    "emotion_model_path = 'fernet_best_1_2.h5'\n",
    "emotion_labels = ['angry', 'happy', 'neutral'] # , 'sad']\n",
    "\n",
    "# hyper-parameters for bounding boxes shape\n",
    "frame_window = 10\n",
    "emotion_offsets = (20, 40)\n",
    "\n",
    "# loading models\n",
    "face_detection = load_detection_model(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "\n",
    "# getting input model shapes for inference\n",
    "emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "\n",
    "# starting lists for calculating modes\n",
    "emotion_window = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CascadeClassifier 000001FE3BE2DCD0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'happy', 'neutral']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9PeMS4ynLxz"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# starting video streaming\n",
    "cv2.namedWindow('window_frame')\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    bgr_image = video_capture.read()[1]\n",
    "    gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "    faces = detect_faces(face_detection, gray_image)\n",
    "    \n",
    "    for face_coordinates in faces:\n",
    "\n",
    "        x1, x2, y1, y2 = apply_offsets(face_coordinates, emotion_offsets)\n",
    "        gray_face = gray_image[y1:y2, x1:x2]\n",
    "        try:\n",
    "            gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        gray_face = preprocess_input(gray_face, True)\n",
    "        gray_face = np.expand_dims(gray_face, 0)\n",
    "        gray_face = np.expand_dims(gray_face, -1)\n",
    "        emotion_prediction = emotion_classifier.predict(gray_face)\n",
    "        emotion_probability = np.max(emotion_prediction)\n",
    "        emotion_label_arg = np.argmax(emotion_prediction)\n",
    "        emotion_text = emotion_labels[emotion_label_arg]\n",
    "        emotion_window.append(emotion_text)\n",
    "\n",
    "        if len(emotion_window) > frame_window:\n",
    "            emotion_window.pop(0)\n",
    "        try:\n",
    "            emotion_mode = mode(emotion_window)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if emotion_text == 'angry':\n",
    "            color = emotion_probability * np.asarray((255, 0, 0))\n",
    "        elif emotion_text == 'happy':\n",
    "            color = emotion_probability * np.asarray((0, 0, 255))\n",
    "        elif emotion_text == 'neutral':\n",
    "            color = emotion_probability * np.asarray((255, 255, 0))\n",
    "        elif emotion_text == 'sad':\n",
    "            color = emotion_probability * np.asarray((0, 255, 255))\n",
    "        else:\n",
    "            color = emotion_probability * np.asarray((0, 255, 0))\n",
    "\n",
    "        color = color.astype(int)\n",
    "        color = color.tolist()\n",
    "\n",
    "        draw_bounding_box(face_coordinates, rgb_image, color)\n",
    "        draw_text(face_coordinates, rgb_image, emotion_mode,\n",
    "                  color, 0, -45, 1, 1)\n",
    "        draw_text(face_coordinates, rgb_image, str(emotion_labels[0])+' : '+str(round(emotion_prediction[0][0],2)),\n",
    "                  [0, 99, 99], 250, 10, 1, 1)\n",
    "        draw_text(face_coordinates, rgb_image, str(emotion_labels[1])+' : '+str(round(emotion_prediction[0][1],2)),\n",
    "                  [99, 0, 99], 250, 60, 1, 1)\n",
    "        draw_text(face_coordinates, rgb_image, str(emotion_labels[2])+' : '+str(round(emotion_prediction[0][2],2)),\n",
    "                  [0, 99, 0], 250, 110, 1, 1)\n",
    "        #draw_text(face_coordinates, rgb_image, str(emotion_labels[3])+' : '+str(round(emotion_prediction[0][3],2)),\n",
    "        #          [0, 0, 0], 250, 160, 1, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    bgr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow('window_frame', bgr_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24739519, 0.27081886, 0.48178592]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor]",
   "language": "python",
   "name": "conda-env-tensor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
